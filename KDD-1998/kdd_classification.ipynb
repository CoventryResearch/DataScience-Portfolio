{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.cross_validation import train_test_split # to divide train and test set\n",
    "from sklearn import preprocessing # for feature scaling\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# import linear model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model evaluation\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Capgemini/Dropbox/Portfolio/DataScience-Portfolio/KDD-1998\n"
     ]
    }
   ],
   "source": [
    "cd Dropbox/Portfolio/DataScience-Portfolio/KDD-1998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and separate in Classifier and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "kdd = pd.read_csv('data_class2.csv')\n",
    "\n",
    "# generate X and Y for preditions\n",
    "Y = np.ravel(kdd.TARGET_B)  # to flatten array\n",
    "X = kdd.drop('TARGET_B', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95149, 1913)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050751978475864171"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean() # very unbalanced class!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature scaling - normalisation\n",
    "def standarisation(train, test):\n",
    "    scaler = preprocessing.StandardScaler().fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test\n",
    "\n",
    "# Feature scaling - MinMax Scaler (scales between 0 and 1)\n",
    "def minMax_standarisation(train, test):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection function\n",
    "def feat_select(model, xtrain, test, ytrain):\n",
    "    selector = model\n",
    "    selector.fit(xtrain, ytrain)\n",
    "    X_train_new = selector.transform(xtrain)\n",
    "    X_test_new = selector.transform(test)\n",
    "    return X_train_new, X_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logReg_mod(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    logit = LogisticRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    logit.fit(Xtrain, Ytrain)\n",
    "    predicted = logit.predict(Xtest)\n",
    "    \n",
    "    print(\"Train set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytrain, logit.predict(Xtrain)))\n",
    "    print('CrossVal: %.3f' % cross_validation.cross_val_score(logit, Xtrain, Ytrain, cv=5).mean())\n",
    "    print('=================')\n",
    "    print(\"Test set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytest, predicted))\n",
    "    print(\"Auc: %.3f\" % roc_auc_score(Ytest, predicted))\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_mod(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    logit = RandomForestClassifier(n_estimators = 500, random_state = 1)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    logit.fit(Xtrain, Ytrain)\n",
    "    predicted = logit.predict(Xtest)\n",
    "    \n",
    "    print(\"Train set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytrain, logit.predict(Xtrain)))\n",
    "    print('CrossVal: %.3f' % cross_validation.cross_val_score(logit, Xtrain, Ytrain, cv=5).mean())\n",
    "    print('=================')\n",
    "    print(\"Test set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytest, predicted))\n",
    "    print(\"Auc: %.3f\" % roc_auc_score(Ytest, predicted))\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_mtx(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data=cm, columns=[0, 1], index=[0, 1])\n",
    "    cm.columns.name = 'Predicted label'\n",
    "    cm.index.name = 'True label'\n",
    "    error_rate = (y_pred != y_test).mean()\n",
    "    print('error rate: %.3f' % error_rate)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split train and test set and normalise predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to split test and train and normalise\n",
    "def split_standarise(X,Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.9, random_state=42)\n",
    "    X_train, X_test = standarisation(X_train, X_test)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9514, 1913), (85635, 1913))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate testing and training set + normalise\n",
    "X_train, X_test, Y_train, Y_test = split_standarise(X,Y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 1763)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Zero Variance features\n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9514, 177), (85635, 177))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select top 10% features\n",
    "X_train, X_test = feat_select(SelectPercentile(f_classif, percentile = 10), X_train, X_test, Y_train)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.953\n",
      "CrossVal: 0.950\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.947\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "# run first log reg model with 234 features\n",
    "logit = logReg_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Log Reg: recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive Feature Selection (RFS)\n",
    "logit_RFS = SelectFromModel(logit, prefit=True)\n",
    "X_train = logit_RFS.transform(X_train)\n",
    "X_test = logit_RFS.transform(X_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.953\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.948\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "logit = logReg_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Third logitstic regression model: select K best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test and normalise\n",
    "X_train, X_test, Y_train, Y_test = split_standarise(X,Y)\n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "\n",
    "# select 10 best features\n",
    "X_train, X_test = feat_select(SelectKBest(f_classif, k=10), X_train, X_test, Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.952\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "# run second log reg model with 10 features\n",
    "logit = logReg_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Log Reg: select features using non normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test and MinMax Scaler\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.9, random_state=42)\n",
    "\n",
    "# use minmax scaler not to generate negative numbers so I can yse chi2 for feature selection\n",
    "X_train, X_test = minMax_standarisation(X_train, X_test) \n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "\n",
    "# select 10 best features\n",
    "X_train, X_test = feat_select(SelectKBest(chi2, k=10), X_train, X_test, Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.952\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "# run log reg model with 10 features\n",
    "logit = logReg_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test and MinMax Scaler\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.9, random_state=42)\n",
    "\n",
    "# use minmax scaler not to generate negative numbers so I can yse chi2 for feature selection\n",
    "X_train, X_test = minMax_standarisation(X_train, X_test) \n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "\n",
    "# select 5 best features\n",
    "X_train, X_test = feat_select(SelectKBest(chi2, k=5), X_train, X_test, Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.952\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "logit = logReg_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Random Forest Model: select 10% best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 1.000\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "# sep train and test, normalise, select top 10% features\n",
    "# separate train and test and normalise\n",
    "X_train, X_test, Y_train, Y_test = split_standarise(X,Y)\n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "X_train, X_test = feat_select(SelectPercentile(f_classif, percentile = 10), X_train, X_test, Y_train)\n",
    "RF = rf_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Random Forest: Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 46)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive Feature Selection (RFS)\n",
    "rf_RFS = SelectFromModel(RF, prefit=True)\n",
    "X_train = rf_RFS.transform(X_train)\n",
    "X_test = rf_RFS.transform(X_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 1.000\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "RF = rf_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Random Forest: select 10 features following feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Feat_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022332</td>\n",
       "      <td>CHIL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014696</td>\n",
       "      <td>AGE904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025689</td>\n",
       "      <td>ETH15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017335</td>\n",
       "      <td>POP90C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016139</td>\n",
       "      <td>POP903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023681</td>\n",
       "      <td>ETH5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008233</td>\n",
       "      <td>POP90C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012833</td>\n",
       "      <td>POP90C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.023291</td>\n",
       "      <td>AGE901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020775</td>\n",
       "      <td>ETH13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature Feat_name\n",
       "0  0.022332     CHIL2\n",
       "1  0.014696    AGE904\n",
       "2  0.025689     ETH15\n",
       "3  0.017335   POP90C4\n",
       "4  0.016139    POP903\n",
       "5  0.023681      ETH5\n",
       "6  0.008233   POP90C2\n",
       "7  0.012833   POP90C3\n",
       "8  0.023291    AGE901\n",
       "9  0.020775     ETH13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = pd.DataFrame(RF.feature_importances_)\n",
    "feat_imp.columns = ['feature']\n",
    "ind = feat_imp.sort_values('feature', axis=0, ascending=False).head(10).index\n",
    "feat_imp['Feat_name'] = pd.Series(X.columns[ind])\n",
    "feat_imp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## best features according to feature importance\n",
    "col_names = feat_imp.Feat_name.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHIL2</th>\n",
       "      <th>AGE904</th>\n",
       "      <th>ETH15</th>\n",
       "      <th>POP90C4</th>\n",
       "      <th>POP903</th>\n",
       "      <th>ETH5</th>\n",
       "      <th>POP90C2</th>\n",
       "      <th>POP90C3</th>\n",
       "      <th>AGE901</th>\n",
       "      <th>ETH13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>332</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>998</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2669</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>219</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHIL2  AGE904  ETH15  POP90C4  POP903  ETH5  POP90C2  POP90C3  AGE901  \\\n",
       "0     42      40      0       47     332    11       35       65      39   \n",
       "1     46      32      1       50     998     6        0        0      34   \n",
       "2     40      37      0       49    2669     2        2       98      35   \n",
       "3     35      34      0       54     219    32        8       92      32   \n",
       "4     43      36      0       46     761     1        0        0      33   \n",
       "\n",
       "   ETH13  \n",
       "0     11  \n",
       "1      2  \n",
       "2      2  \n",
       "3     31  \n",
       "4      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reduce original dataset to 10 features following Random Forest Importance\n",
    "new_X = X[col_names]\n",
    "new_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.994\n",
      "CrossVal: 0.948\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.945\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_standarise(new_X,Y)\n",
    "RF = rf_mod(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Random Forest with unbalanced samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_mod2(Xtrain, Ytrain, Xtest, Ytest, sample_weights):\n",
    "    logit = RandomForestClassifier(n_estimators = 500, random_state = 1)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    logit.fit(Xtrain, Ytrain, sample_weight = sample_weight)\n",
    "    predicted = logit.predict(Xtest)\n",
    "    \n",
    "    print(\"Train set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytrain, logit.predict(Xtrain)))\n",
    "    print('CrossVal: %.3f' % cross_validation.cross_val_score(logit, Xtrain, Ytrain, cv=5).mean())\n",
    "    print('=================')\n",
    "    print(\"Test set\")\n",
    "    print(\"Accuracy: %.3f\" % metrics.accuracy_score(Ytest, predicted))\n",
    "    print(\"Auc: %.3f\" % roc_auc_score(Ytest, predicted))\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regenerate train and test set, and select 10% best features\n",
    "X_train, X_test, Y_train, Y_test = split_standarise(X,Y)\n",
    "X_train, X_test = feat_select(VarianceThreshold(), X_train, X_test, Y_train)\n",
    "X_train, X_test = feat_select(SelectPercentile(f_classif, percentile = 10), X_train, X_test, Y_train)\n",
    "\n",
    "sample_weight = np.array([20 if i == 1 else 1 for i in Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 1.000\n",
      "CrossVal: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "RF = rf_mod2(X_train, Y_train, X_test, Y_test, sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9514, 177)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbparams = {'learning_rate' : 0.1, \n",
    "                     'n_estimators': 50,\n",
    "                     'max_depth': 5,\n",
    "                     'min_child_weight': 1,\n",
    "                     'gamma': 0,\n",
    "                     'subsample': 0.8,\n",
    "                     'colsample_bytree': 0.8,\n",
    "                     'objective' : 'binary:logistic',\n",
    "                     'nthread': 4,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'seed' : 27}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_child_weight': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(xgbparams, nthread=-1)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_model,\n",
    "    {\n",
    "        'max_depth': [1,3,5,7,9],\n",
    "        'min_child_weight':[1,3,5,7]\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=1,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6, 'subsample': 0.6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import ndcg_scorer\n",
    "xgbparams = {'learning_rate' : 0.1, \n",
    "                     'n_estimators': 50,\n",
    "                     'max_depth': 3,\n",
    "                     'min_child_weight': 1,\n",
    "                     'gamma': 0,\n",
    "                     'subsample': 0.8,\n",
    "                     'colsample_bytree': 0.8,\n",
    "                     'objective' : 'binary:logistic',\n",
    "                     'nthread': 4,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'seed' : 27}\n",
    "\n",
    "xgb_model = XGBClassifier(xgbparams, nthread=-1)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_model,\n",
    "    {\n",
    "    'subsample':[i/10 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10 for i in range(6,10)],\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=1,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise regularisation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 1e-05}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbparams = {'learning_rate' : 0.1, \n",
    "                     'n_estimators': 50,\n",
    "                     'max_depth': 3,\n",
    "                     'min_child_weight': 1,\n",
    "                     'gamma': 0,\n",
    "                     'subsample': 0.6,\n",
    "                     'colsample_bytree': 0.6,\n",
    "                     'objective' : 'binary:logistic',\n",
    "                     'nthread': 4,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'seed' : 27}\n",
    "\n",
    "xgb_model = XGBClassifier(xgbparams, nthread=-1)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_model,\n",
    "    {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]},\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=1,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise learning rate and number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'n_estimators': 10}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbparams = {'learning_rate' : 0.1, \n",
    "                     'n_estimators': 50,\n",
    "                     'max_depth': 3,\n",
    "                     'min_child_weight': 1,\n",
    "                     'gamma': 0,\n",
    "                     'subsample': 0.6,\n",
    "                     'colsample_bytree': 0.6,\n",
    "                     'objective' : 'binary:logistic',\n",
    "                     'nthread': 4,\n",
    "                     'scale_pos_weight': 1,\n",
    "                     'reg_alpha': 1e-05,\n",
    "                     'seed' : 27}\n",
    "\n",
    "xgb_model = XGBClassifier(xgbparams, nthread=-1)\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_model,\n",
    "    {'learning_rate':[0.01, 0.03, 0.1, 0.3, 1],\n",
    "    'n_estimators':[10, 100, 500, 1000]},\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=1,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_train = clf.predict(X_train)\n",
    "predictions_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Accuracy: 0.952\n",
      "=================\n",
      "Test set\n",
      "Accuracy: 0.949\n",
      "Auc: 0.500\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set\")\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(Y_train, predictions_train))\n",
    "print('=================')\n",
    "print(\"Test set\")\n",
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(Y_test, predictions_test))\n",
    "print(\"Auc: %.3f\" % roc_auc_score(Y_test, predictions_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
